{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subiectul 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Descarcam baza de date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.cm import binary\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit_image = X[1].reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap=binary, interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am luat 1000 de elemente lucra mai usor si a configura mai rapid codul scris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=X[:1000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folosim Metoda Elbow pentru a gasi numarul de clustere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the Elbow method\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "\n",
    "Ks = range(1,800,100)\n",
    "km = [KMeans(n_clusters=i) for i in Ks]\n",
    "#score = [km[i].fit(X).inertia_ for i in range(len(km))]\n",
    "score = [km[i].fit(X1).inertia_ for i in range(len(km))]\n",
    "plt.plot(Ks,score,'-ob')\n",
    "plt.xlabel('Number of clusters',fontsize=20)\n",
    "plt.ylabel('Objective function',fontsize=20)\n",
    "plt.title(\"Elbow method\",fontsize=20)\n",
    "plt.suptitle(\"Elbow method for KMeans clustering on sample data\",fontsize=14, fontweight='bold')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folosim si o alta metoda pentru a aproxima numarul de clustere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "range_n_clusters = [2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "X1=X[:1000]\n",
    "(fig,axes) = plt.subplots(1,len(range_n_clusters))\n",
    "fig.set_size_inches(18, 10)\n",
    "current_axis = 0;\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    \n",
    "    axes[current_axis].set_xlim([-0.1, 1])\n",
    "    axes[current_axis].set_ylim([0, len(X1) + (n_clusters + 1) * 10])\n",
    "\n",
    "    clusterer = KMeans(n_clusters=n_clusters,algorithm='elkan', random_state=rand_state)\n",
    "    cluster_labels = clusterer.fit_predict(X1)\n",
    "\n",
    "    silhouette_avg = silhouette_score(X1, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "    \n",
    "    sample_silhouette_values = silhouette_samples(X1, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.Spectral(float(i) / n_clusters)\n",
    "        axes[current_axis].fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        axes[current_axis].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    axes[current_axis].set_title(\"Silhouette plot for %d clusters\"%n_clusters)\n",
    "    axes[current_axis].set_xlabel(\"Silhouette coefficient values\")\n",
    "    axes[current_axis].set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    axes[current_axis].axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    axes[current_axis].set_yticks([])\n",
    "    axes[current_axis].set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    current_axis = current_axis+1\n",
    "    plt.suptitle(\"Silhouette analysis for KMeans clustering on sample data\",\n",
    "                 fontsize=14, fontweight='bold')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicam un algoritm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "n_digits = len(np.unique(y))\n",
    "print(n_digits)\n",
    "\n",
    "# Initialize KMeans model\n",
    "kmeans = MiniBatchKMeans(n_clusters = n_digits)\n",
    "\n",
    "# Fit the model to the training data\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics.cluster import v_measure_score\n",
    "\n",
    "def calculate_metrics(estimator, data, labels):\n",
    "    # Calculate and print metrics\n",
    "    print('Number of Clusters: {}'.format(estimator.n_clusters))\n",
    "    print('Inertia: {}'.format(estimator.inertia_))\n",
    "    print('Homogeneity: {}'.format(metrics.homogeneity_score(labels, estimator.labels_)))\n",
    "    print('V measure score: {}'.format(v_measure_score(labels, estimator.labels_)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "print('Train Data: ', X_train, '\\n', 'Test Data:', X_test, '\\n','Train label: ', y_train, '\\n', 'Test Label: ', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_cluster_labels(kmeans, actual_labels):\n",
    "   \n",
    "    inferred_labels = {}\n",
    "\n",
    "    for i in range(kmeans.n_clusters):\n",
    "\n",
    "        # find index of points in cluster\n",
    "        labels = []\n",
    "        index = np.where(kmeans.labels_ == i)\n",
    "\n",
    "        # append actual labels for each point in cluster\n",
    "        labels.append(actual_labels[index])\n",
    "\n",
    "        # determine most common label\n",
    "        if len(labels[0]) == 1:\n",
    "            counts = np.bincount(labels[0])\n",
    "        else:\n",
    "            counts = np.bincount(np.squeeze(labels))\n",
    "\n",
    "        # assign the cluster to a value in the inferred_labels dictionary\n",
    "        if np.argmax(counts) in inferred_labels:\n",
    "            # append the new number to the existing array at this slot\n",
    "            inferred_labels[np.argmax(counts)].append(i)\n",
    "        else:\n",
    "            # create a new array in this slot\n",
    "            inferred_labels[np.argmax(counts)] = [i]\n",
    "\n",
    "        #print(labels)\n",
    "        #print('Cluster: {}, label: {}'.format(i, np.argmax(counts)))\n",
    "        \n",
    "    return inferred_labels  \n",
    "\n",
    "def infer_data_labels(X_labels, cluster_labels):\n",
    "    \n",
    "    # empty array of len(X)\n",
    "    predicted_labels = np.zeros(len(X_labels)).astype(np.uint8)\n",
    "    \n",
    "    for i, cluster in enumerate(X_labels):\n",
    "        for key, value in cluster_labels.items():\n",
    "            if cluster in value:\n",
    "                predicted_labels[i] = key\n",
    "                \n",
    "    return predicted_labels\n",
    "# test the infer_cluster_labels() and infer_data_labels() functions\n",
    "cluster_labels = infer_cluster_labels(kmeans, y)\n",
    "X_clusters = kmeans.predict(X)\n",
    "predicted_labels = infer_data_labels(X_clusters, cluster_labels)\n",
    "print(predicted_labels[:20])\n",
    "print(y[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [10, 16, 36, 64, 144, 256]\n",
    "\n",
    "# test different numbers of clusters\n",
    "for n_clusters in clusters:\n",
    "    estimator = MiniBatchKMeans(n_clusters = n_clusters)\n",
    "    estimator.fit(X5)\n",
    "    \n",
    "    # print cluster metrics\n",
    "    calculate_metrics(estimator, X5, Y)\n",
    "    \n",
    "    # determine predicted labels\n",
    "    cluster_labels = infer_cluster_labels(estimator, Y)\n",
    "    predicted_Y = infer_data_labels(estimator.labels_, cluster_labels)\n",
    "    \n",
    "    # calculate and print accuracy\n",
    "    print('Accuracy: {}\\n'.format(metrics.accuracy_score(Y, predicted_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
